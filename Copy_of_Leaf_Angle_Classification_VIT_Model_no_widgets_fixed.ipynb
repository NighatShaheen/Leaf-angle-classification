{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"avTBFhQaqlbJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/NighatShaheen/Leaf-angle-classification.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nj0cd0b26Im_","executionInfo":{"status":"ok","timestamp":1766974860445,"user_tz":-60,"elapsed":734,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"9c16bbaf-fea2-455a-b795-7ca6f417ed03"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Leaf-angle-classification'...\n","remote: Enumerating objects: 23, done.\u001b[K\n","remote: Counting objects: 100% (23/23), done.\u001b[K\n","remote: Compressing objects: 100% (20/20), done.\u001b[K\n","remote: Total 23 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (23/23), 11.95 KiB | 3.98 MiB/s, done.\n","Resolving deltas: 100% (10/10), done.\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Colab_Notebooks/Copy_of_Leaf_Angle_Classification_VIT_Model_no_widgets_fixed.ipynb\" \\\n","\"/content/Leaf_angle_classification/Copy_of_Leaf_Angle_Classification_VIT_Model_no_widgets_fixed.ipynb\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEoNZGNm6rOW","executionInfo":{"status":"ok","timestamp":1766975450971,"user_tz":-60,"elapsed":108,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"7bc7850f-698f-4eee-a6b3-a69d73c02cb6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/MyDrive/Colab_Notebooks/Copy_of_Leaf_Angle_Classification_VIT_Model_no_widgets_fixed.ipynb': No such file or directory\n"]}]},{"cell_type":"code","source":["!ls -la \"/content/drive/MyDrive\" | sed -n '1,80p'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9uy9gslo8qPH","executionInfo":{"status":"ok","timestamp":1766975532332,"user_tz":-60,"elapsed":77,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"f13a989b-b812-4d2a-fff9-4f8ffbeea5d6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/content/drive/MyDrive': No such file or directory\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nst2yUf68qRs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cE120NsS8qVK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rLzZvf3z6rRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","root = Path(\"/content/drive/MyDrive/Colab Notebooks\")\n","[x.name for x in root.iterdir()][:50]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9Uu5c-zsfyq","executionInfo":{"status":"ok","timestamp":1766971435774,"user_tz":-60,"elapsed":36,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"8ae687f7-4c9f-43db-d48c-2346463ac790"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['leafclassification11.ipynb',\n"," 'Copy of vision_transformer_leaf_angle.ipynb',\n"," 'Copy of Vision Transformer (ViT) on CIFAR-10 from scratch using PyTorch.ipynb',\n"," 'Leaf_Angle_Classidifcation_VIT.ipynb',\n"," 'Untitled8.ipynb',\n"," 'Untitled1.ipynb',\n"," 'Vision Transformer (ViT) on CIFAR-10 from scratch using PyTorch.ipynb',\n"," 'Leaf_Angle_Classification_VIT_Model.ipynb',\n"," 'Copy_of_Leaf_Angle_Classification_VIT_Model.ipynb']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","\n","path = Path(\"/content/drive/MyDrive/Colab_Notebooks/Copy_of_Leaf_Angle_Classification_VIT_Model.ipynb\")\n","\n","nb = json.loads(path.read_text(encoding=\"utf-8\"))\n","\n","# Remove broken widgets metadata\n","nb.get(\"metadata\", {}).pop(\"widgets\", None)\n","\n","# Remove per-cell widget metadata too (just in case)\n","for cell in nb.get(\"cells\", []):\n","    cell.get(\"metadata\", {}).pop(\"widgets\", None)\n","\n","fixed_path = path.with_name(path.stem + \"_fixed.ipynb\")\n","fixed_path.write_text(json.dumps(nb, ensure_ascii=False, indent=1), encoding=\"utf-8\")\n","\n","print(\"Fixed notebook saved to:\", fixed_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2Zm4B8dsf8E","executionInfo":{"status":"ok","timestamp":1766971542975,"user_tz":-60,"elapsed":468,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"9021fa02-d16d-4d1b-a686-912062d2ffc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fixed notebook saved to: /content/drive/MyDrive/Colab_Notebooks/Copy_of_Leaf_Angle_Classification_VIT_Model_fixed.ipynb\n"]}]},{"cell_type":"code","source":["import json\n","\n","path = \"/content/drive/MyDrive/Colab_Notebooks/Copy_of_Leaf_Angle_Classification_VIT_Model.ipynb\"  # change this\n","with open(path, \"r\", encoding=\"utf-8\") as f:\n","    nb = json.load(f)\n","\n","md = nb.setdefault(\"metadata\", {})\n","w = md.setdefault(\"widgets\", {})\n","w.setdefault(\"state\", {})\n","w.setdefault(\"version_major\", 2)\n","w.setdefault(\"version_minor\", 0)\n","\n","fixed_path = path.replace(\".ipynb\", \"_fixed.ipynb\")\n","with open(fixed_path, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(nb, f, ensure_ascii=False, indent=1)\n","\n","fixed_path\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"oV8ryE5EtQLk","executionInfo":{"status":"ok","timestamp":1766971686229,"user_tz":-60,"elapsed":450,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"f422a9a0-51e2-4840-ff8f-5371b31e3de2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab_Notebooks/Copy_of_Leaf_Angle_Classification_VIT_Model_fixed.ipynb'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","\n","path = Path(\"/content/drive/MyDrive/Colab_Notebooks/Copy_of_Leaf_Angle_Classification_VIT_Model.ipynb\")  # change if needed\n","nb = json.loads(path.read_text(encoding=\"utf-8\"))\n","\n","print(\"Has metadata.widgets?\", \"widgets\" in nb.get(\"metadata\", {}))\n","print(\"metadata.widgets keys:\", list(nb.get(\"metadata\", {}).get(\"widgets\", {}).keys()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rRUOP0NtQTg","executionInfo":{"status":"ok","timestamp":1766971808941,"user_tz":-60,"elapsed":250,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"7ecc845c-6470-4533-cfdd-fc79a37ba314"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Has metadata.widgets? True\n","metadata.widgets keys: ['application/vnd.jupyter.widget-state+json']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Z7naHRlctQe9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVw2e2e5TxKk","colab":{"base_uri":"https://localhost:8080/","height":738,"referenced_widgets":["b44dbd9b53184bff8904c7439345c369","f75ac446010e4057a9cae071dffef93a","7f5cc9092ba64dde818504e8337c6ce9","5fb6b21b022e40b8b4d94e9fa1f4f51a","b6e06253ab48494bacc946e34fc18fb4","c216db6d967741b4a35cd328d825170e","2a0334c62402413f802d9b4d2a11f4c8","245846629b544fb1b931274cf62116c7","f38fd6f2a9a644f48fd1c201f0d8a5fb","5637346594304cf6b8f005e903dbe999","7aff8e5066d7456db1ae1d1e297c84d6","4b70142493a94d4c80eb2511f7f36996","f1d4378d6d9a46b6bfb21fdd6279c37e","640ee2755de645449cb30f2cf2214808","663c5b9a69e84a5ca7007b64358d9e6e","6e71bae08954486da52a88e03d065911","fd08689516c34e2bb311fd371975b8cd","ece479f00daa40eb99e3e05f54785ed0","a9cc3f8e32984e06ab5ac1fffb3b9995","3008d74f42744d8b9c33ef31061e6637","e42d16244c5c4538a0e41e569b9e5558","64ded5c284f64dc9a0975702aa2657c3","0874ed02487a452bb43f9f25ea75f95e","b68a53a5973e417280b539964ef3a579","4da3576b2f3a452091cd2d62fe9e7214","87f2f2f071844a66856ee154e33e9a70","a811f29290f046c49b852156ae30b54a","a8766ce8add94328b7144e36e5392ff1","72c4f85f04934803b15da41545a143f6","a36d834d1a4447f6916ac45914e0423d","91ca96a9b3d842b0924f3194f7e91144","b7b88f5a00534562b13a8ed89b3b9ce0","16d309116e3246a2934d24b52342dbac"]},"executionInfo":{"status":"error","timestamp":1766594183317,"user_tz":-60,"elapsed":794812,"user":{"displayName":"Nighat Shaheen","userId":"17851468490215380072"}},"outputId":"910d7596-87fe-4a9e-8ffc-8b793685ba1e"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b44dbd9b53184bff8904c7439345c369"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b70142493a94d4c80eb2511f7f36996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0874ed02487a452bb43f9f25ea75f95e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([5]) in the model instantiated\n","- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1066176477.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","from transformers import ViTImageProcessor, ViTForImageClassification\n","from torch.optim import AdamW\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define output_folder here to ensure it's in scope\n","output_folder = '/content/drive/MyDrive/Final_Pisek_dataset'\n","\n","# -----------------------------\n","# Config\n","# -----------------------------\n","MODEL_ID = \"google/vit-base-patch16-224\"  # ViT-B/16 (Corrected from patch32)\n","# TRAIN_DIR and VAL_DIR are not needed as we will use the existing output_folder\n","# and split it.\n","NUM_CLASSES = 5                           # <-- set this\n","BATCH_SIZE = 16\n","EPOCHS = 5\n","LR = 1e-3                                 # higher LR is ok when training only head\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# -----------------------------\n","# Model + Processor\n","# -----------------------------\n","processor = ViTImageProcessor.from_pretrained(MODEL_ID)\n","model = ViTForImageClassification.from_pretrained(\n","    MODEL_ID,\n","    num_labels=NUM_CLASSES,\n","    ignore_mismatched_sizes=True\n",").to(device)\n","\n","# Optional: set class labels (nice for inference)\n","# If you use ImageFolder, class order is alphabetical by folder name.\n","# We'll set these after creating the dataset.\n","\n","# -----------------------------\n","# Freeze backbone (train head only)\n","# -----------------------------\n","for p in model.vit.parameters():\n","    p.requires_grad = False\n","\n","# Ensure classifier is trainable (it will be, but explicit is nice)\n","for p in model.classifier.parameters():\n","    p.requires_grad = True\n","\n","# -----------------------------\n","# Data preparation using existing output_folder\n","# -----------------------------\n","# Define a raw ImageFolder dataset that yields PIL images (no ToTensor here)\n","\n","# Explicitly check if the directory exists\n","if not os.path.isdir(output_folder):\n","    raise FileNotFoundError(\n","        f\"Directory not found: {output_folder}. \"\n","        \"Please ensure Google Drive is mounted and the path is correct.\"\n","        \"You may need to re-run the `drive.mount('/content/drive')` cell if it was not executed recently.\"\n","    )\n","\n","full_raw_dataset = ImageFolder(root=output_folder)\n","\n","# Split the full dataset into training and validation subsets\n","train_size = int(0.8 * len(full_raw_dataset))\n","val_size = len(full_raw_dataset) - train_size\n","hf_train_subset, hf_val_subset = torch.utils.data.random_split(full_raw_dataset, [train_size, val_size])\n","\n","# Custom Dataset class to apply the HuggingFace processor's transform\n","class HFTransformedDataset(torch.utils.data.Dataset):\n","    def __init__(self, subset, processor_transform):\n","        self.subset = subset\n","        self.processor_transform = processor_transform\n","\n","    def __getitem__(self, idx):\n","        # subset[idx] returns (PIL_image, label) because full_raw_dataset has no ToTensor\n","        image, label = self.subset[idx]\n","        # Apply the HuggingFace processor transform to the PIL image\n","        processed_pixel_values = self.processor_transform(images=image.convert(\"RGB\"), return_tensors=\"pt\")[\"pixel_values\"][0]\n","        return processed_pixel_values, label\n","\n","    def __len__(self):\n","        return len(self.subset)\n","\n","train_ds = HFTransformedDataset(hf_train_subset, processor_transform=processor)\n","val_ds   = HFTransformedDataset(hf_val_subset,   processor_transform=processor)\n","\n","# Set id2label / label2id from the full raw ImageFolder classes\n","id2label = {i: c for i, c in enumerate(full_raw_dataset.classes)}\n","label2id = {c: i for c, i in id2label.items()}\n","model.config.id2label = id2label\n","model.config.label2id = label2id\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# -----------------------------\n","# Optimizer (ONLY head params)s\n","# -----------------------------\n","optimizer = AdamW(model.classifier.parameters(), lr=LR)\n","\n","# -----------------------------\n","# Train / Eval\n","# -----------------------------\n","def accuracy_on_loader(loader):\n","    model.eval()\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            logits = model(pixel_values=x).logits\n","            preds = logits.argmax(dim=-1)\n","            correct += (preds == y).sum().item()\n","            total += y.numel()\n","    return correct / max(total, 1)\n","\n","for epoch in range(1, EPOCHS + 1):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for x, y in train_loader:\n","        x, y = x.to(device), y.to(device)\n","\n","        outputs = model(pixel_values=x, labels=y)\n","        loss = outputs.loss\n","\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    train_acc = accuracy_on_loader(train_loader)\n","    val_acc = accuracy_on_loader(val_loader)\n","\n","    print(f\"Epoch {epoch}/{EPOCHS} | loss={total_loss/len(train_loader):.4f} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f}\")\n","\n","# -----------------------------\n","# Save\n","# -----------------------------\n","os.makedirs(\"vitb32_head_finetuned\", exist_ok=True)\n","model.save_pretrained(\"vitb32_head_finetuned\")\n","processor.save_pretrained(\"vitb32_head_finetuned\")\n","print(\"Saved to vitb32_head_finetuned/\")"]},{"cell_type":"code","source":[],"metadata":{"id":"NTdOMt4F3OF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"44IQYnMe3OKC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bGVkenYx3OOp"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1QhohXwGGQ4klky01t3ZYCFbc8-15tM4f","timestamp":1766970451362}],"authorship_tag":"ABX9TyPMr0PmZ0Vv2GGhGQ2UZBas"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}